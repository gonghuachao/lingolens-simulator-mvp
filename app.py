import streamlit as st
import os
import time
import json
import google.generativeai as genai
from PIL import Image
import io
from google.cloud import texttospeech

# é…ç½® Gemini API
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])

def get_tts_audio(text_to_speak):
    """
    ä½¿ç”¨ Google Cloud Text-to-Speech API å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³
    
    Args:
        text_to_speak: è¦è½¬æ¢çš„è‹±æ–‡æ–‡æœ¬
        
    Returns:
        bytes: éŸ³é¢‘æ•°æ®ï¼Œå¦‚æœè½¬æ¢å¤±è´¥åˆ™è¿”å› None
    """
    try:
        # åˆå§‹åŒ– Text-to-Speech å®¢æˆ·ç«¯
        client = texttospeech.TextToSpeechClient()
        
        # è®¾ç½®è¦åˆæˆçš„æ–‡æœ¬
        synthesis_input = texttospeech.SynthesisInput(text=text_to_speak)
        
        # é…ç½®è¯­éŸ³å‚æ•°
        voice = texttospeech.VoiceSelectionParams(
            language_code="en-US",
            name="en-US-Wavenet-F",  # ä½¿ç”¨å¥³å£°
            ssml_gender=texttospeech.SsmlVoiceGender.FEMALE
        )
        
        # é…ç½®éŸ³é¢‘æ ¼å¼
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3,
            speaking_rate=0.9,  # ç¨å¾®æ”¾æ…¢è¯­é€Ÿï¼Œä½¿å…¶æ›´æ¸…æ™°
            pitch=0  # é»˜è®¤éŸ³é«˜
        )
        
        # æ‰§è¡Œæ–‡æœ¬åˆ°è¯­éŸ³çš„è½¬æ¢
        response = client.synthesize_speech(
            input=synthesis_input,
            voice=voice,
            audio_config=audio_config
        )
        
        # è¿”å›éŸ³é¢‘å†…å®¹
        return response.audio_content
        
    except Exception as e:
        st.error(f"æ–‡æœ¬è½¬è¯­éŸ³å¤±è´¥: {str(e)}")
        return None

def analyze_image_for_words(image_bytes):
    """
    åˆ†æå›¾ç‰‡ä¸­çš„ç‰©ä½“å¹¶è¿”å›è‹±æ–‡å’Œä¸­æ–‡åç§°
    
    Args:
        image_bytes: å›¾ç‰‡çš„å­—èŠ‚æ•°æ®
        
    Returns:
        list: åŒ…å«ç‰©ä½“ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å« 'english_name' å’Œ 'chinese_name'
    """
    try:
        # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸ºPIL Imageå¯¹è±¡
        image = Image.open(io.BytesIO(image_bytes))
        
        # é…ç½®æ¨¡å‹
        model = genai.GenerativeModel('gemini-pro-vision')
        
        # æ„å»ºæç¤ºè¯
        prompt = """Identify the main objects in the provided image. For each object, give its name in English and its translation in Simplified Chinese. 
        Please return the result as a JSON list of objects, where each object has 'english_name' and 'chinese_name' keys. 
        For example: [{'english_name': 'mug', 'chinese_name': 'é©¬å…‹æ¯'}, {'english_name': 'key', 'chinese_name': 'é’¥åŒ™'}]. 
        Only return the JSON list."""
        
        # ç”Ÿæˆå“åº”
        response = model.generate_content([prompt, image])
        
        # å°è¯•è§£æJSONå“åº”
        try:
            # æå–å“åº”æ–‡æœ¬å¹¶è§£æJSON
            response_text = response.text.strip()
            # ç¡®ä¿å“åº”æ–‡æœ¬æ˜¯æœ‰æ•ˆçš„JSONå­—ç¬¦ä¸²
            if response_text.startswith('[') and response_text.endswith(']'):
                objects_list = json.loads(response_text)
                return objects_list
            else:
                st.error("AIå“åº”æ ¼å¼ä¸æ­£ç¡®")
                return []
        except json.JSONDecodeError:
            st.error("æ— æ³•è§£æAIå“åº”ä¸ºJSONæ ¼å¼")
            return []
            
    except Exception as e:
        st.error(f"åˆ†æå›¾ç‰‡æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return []

st.set_page_config(layout="wide")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€å˜é‡
if 'conversation' not in st.session_state:
    st.session_state.conversation = []
if 'feedback_log' not in st.session_state:
    st.session_state.feedback_log = []
if 'current_image' not in st.session_state:
    st.session_state.current_image = None
if 'audio_filename' not in st.session_state:
    st.session_state.audio_filename = None
if 'is_recording' not in st.session_state:
    st.session_state.is_recording = False
if 'analyzed_objects' not in st.session_state:
    st.session_state.analyzed_objects = []

# æ ‡é¢˜
st.title("LingoLens MVP Simulator")

# ä¸Šä¸‹æ–‡æ•è·éƒ¨åˆ†
st.subheader("Capture Context (Optional)")
img_file_buffer = st.camera_input("Take Photo")
if img_file_buffer is not None:
    st.session_state.current_image = img_file_buffer
    st.image(img_file_buffer, caption="å·²æ•è·çš„å›¾åƒ", width=300)
    
    # æ·»åŠ åˆ†ææŒ‰é’®
    if st.button("Analyze Photo for Words"):
        if st.session_state.current_image is not None:
            with st.spinner('Analyzing image...'):
                # è°ƒç”¨åˆ†æå‡½æ•°
                analysis_results = analyze_image_for_words(st.session_state.current_image.getvalue())
                # å­˜å‚¨åˆ†æç»“æœåˆ°ä¼šè¯çŠ¶æ€
                st.session_state.analyzed_objects = analysis_results
                # è§¦å‘é¡µé¢åˆ·æ–°
                st.rerun()
    
    # åˆ›å»ºåˆ†æç»“æœæ˜¾ç¤ºåŒºåŸŸ
    object_analysis_area = st.container()
    with object_analysis_area:
        st.markdown("### Analysis Results")
        if st.session_state.analyzed_objects:
            st.markdown("#### è¯†åˆ«åˆ°çš„ç‰©ä½“ï¼š")
            for obj in st.session_state.analyzed_objects:
                # ä¸ºæ¯ä¸ªç‰©ä½“åˆ›å»ºä¸€ä¸ªå®¹å™¨
                with st.container():
                    # åˆ›å»ºä¸‰åˆ—å¸ƒå±€
                    col1, col2, col3 = st.columns([2, 2, 1])
                    with col1:
                        st.markdown(f"**{obj['english_name']}**")
                    with col2:
                        st.markdown(f"{obj['chinese_name']}")
                    with col3:
                        # ä½¿ç”¨è‹±æ–‡åä½œä¸ºæŒ‰é’®çš„å”¯ä¸€é”®
                        if st.button("ğŸ”Š", key=f"pronounce_{obj['english_name']}"):
                            # æ˜¾ç¤ºç”Ÿæˆæç¤º
                            with st.spinner(f'æ­£åœ¨ç”Ÿæˆ {obj["english_name"]} çš„å‘éŸ³...'):
                                # è·å–éŸ³é¢‘æ•°æ®
                                audio_bytes = get_tts_audio(obj['english_name'])
                                if audio_bytes:
                                    # æ’­æ”¾éŸ³é¢‘
                                    st.audio(audio_bytes, format='audio/mp3')
                                else:
                                    st.error(f"æ— æ³•ç”Ÿæˆ {obj['english_name']} çš„å‘éŸ³")
                # æ·»åŠ åˆ†éš”çº¿
                st.markdown("---")
        else:
            st.info("ç‚¹å‡» 'Analyze Photo for Words' æŒ‰é’®å¼€å§‹åˆ†æå›¾ç‰‡")

# ä¸»äº¤äº’åŒºåŸŸ
st.subheader("Talk to LingoLens AI")

# èŠå¤©å†å²å®¹å™¨
chat_container = st.container()
with chat_container:
    # è®¾ç½®èŠå¤©å†å²å®¹å™¨çš„é«˜åº¦
    st.markdown("""
        <style>
        .chat-container {
            height: 400px;
            overflow-y: auto;
        }
        </style>
    """, unsafe_allow_html=True)
    
    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state.conversation:
        with st.chat_message(message['role']):
            st.write(message['text'])

# è¾“å…¥åŒºåŸŸ
st.subheader("Input")
record_col1, record_col2 = st.columns(2)
with record_col1:
    st.button("ğŸ¤ Start Recording")
with record_col2:
    st.button("â¹ï¸ Stop Recording")

# æ·»åŠ éŸ³é¢‘æ’­æ”¾å™¨
if st.session_state.audio_filename and os.path.exists(st.session_state.audio_filename):
    try:
        with open(st.session_state.audio_filename, 'rb') as audio_file:
            audio_bytes = audio_file.read()
            st.audio(audio_bytes, format='audio/wav')
    except FileNotFoundError:
        st.error("éŸ³é¢‘æ–‡ä»¶æœªæ‰¾åˆ°")
    except Exception as e:
        st.error(f"æ’­æ”¾éŸ³é¢‘æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
    finally:
        # å¯é€‰ï¼šåˆ é™¤ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
        try:
            os.remove(st.session_state.audio_filename)
        except:
            pass

# æ–‡æœ¬è¾“å…¥å’Œå‘é€æŒ‰é’®
user_input = st.text_input("Or type your message here:")
st.button("Send to AI")

# æ•™ç»ƒåé¦ˆéƒ¨åˆ†
st.subheader("Coach Feedback")
feedback_container = st.container()
with feedback_container:
    # è®¾ç½®åé¦ˆå®¹å™¨çš„é«˜åº¦
    st.markdown("""
        <style>
        .feedback-container {
            height: 200px;
            overflow-y: auto;
        }
        </style>
    """, unsafe_allow_html=True)
    
    for feedback in st.session_state.feedback_log:
        st.write(feedback)








